{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtyISKU12tvY"
      },
      "source": [
        "# **Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFueH95RxC1z",
        "outputId": "8ccabddf-572a-4b7d-95fb-88d9729b43a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-15 09:24:26--  http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.101.207, 142.251.2.207, 74.125.137.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.101.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182082353 (174M) [application/zip]\n",
            "Saving to: â€˜mini_speech_commands.zipâ€™\n",
            "\n",
            "mini_speech_command 100%[===================>] 173.65M   204MB/s    in 0.9s    \n",
            "\n",
            "2025-12-15 09:24:27 (204 MB/s) - â€˜mini_speech_commands.zipâ€™ saved [182082353/182082353]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\n",
        "!unzip -q mini_speech_commands.zip -d ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg1c9Uq22z8F"
      },
      "source": [
        "# **Importing the required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R3i4DaWxzvxz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import librosa\n",
        "from scipy.fft import fft\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "\n",
        "import glob\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm1BXDtP284f"
      },
      "source": [
        "# **Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EL6pk6vtz3Fy"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "DATA_PATH = \"/content/mini_speech_commands\"  # The Data path\n",
        "CLASSES = ['yes', 'no', 'up', 'down', 'left', 'right', 'go', 'stop'] # The 8 target classes\n",
        "\n",
        "FRAME_LENGTH = 256      # 16ms at 16kHz [ sr=16000 â†’ frame duration = 256/16000 = 0.016 s = 16 ms. ]\n",
        "HOP_LENGTH = 128        # 8ms step (50% overlap)\n",
        "SAMPLE_RATE = 16000     # Standard for speech\n",
        "\n",
        "N_MELS = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMJREuXp2pWP"
      },
      "source": [
        "# **Preprocessing for the audio file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T9hE8hC5z9RD"
      },
      "outputs": [],
      "source": [
        "# Process one WAV file and return its average spectrum\n",
        "def process_audio_file(file_path):\n",
        "\n",
        "    # Load audio file\n",
        "    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE) # Loads audio, resamples to 16 kHz, and converts to mono by default.\n",
        "\n",
        "    # Divide into frames\n",
        "    frames = []\n",
        "    for i in range(0, len(signal) - FRAME_LENGTH, HOP_LENGTH):\n",
        "        frame = signal[i:i + FRAME_LENGTH]\n",
        "        frames.append(frame)\n",
        "\n",
        "    # Apply FFT to each frame and get magnitude spectrum\n",
        "    spectra = []\n",
        "    for frame in frames:\n",
        "        # Apply window function (Hamming) to reduce spectral leakage\n",
        "        windowed_frame = frame * np.hamming(FRAME_LENGTH)\n",
        "\n",
        "        # Compute FFT and get magnitude\n",
        "        spectrum = np.abs(fft(windowed_frame)) # absolute -> magnitude\n",
        "\n",
        "\n",
        "        # Keep only first half (real FFT symmetry)\n",
        "        spectrum = spectrum[:FRAME_LENGTH//2]\n",
        "\n",
        "        spectra.append(spectrum)\n",
        "\n",
        "    # Average all frames in this file\n",
        "    if len(spectra) > 0:\n",
        "        file_average_spectrum = np.mean(spectra, axis=0)\n",
        "        return file_average_spectrum\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbgNhVPm2kmD"
      },
      "source": [
        "# **Training Phase**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HQdL8H9x0A1S"
      },
      "outputs": [],
      "source": [
        "# Train the distance-based system by creating templates for each class\n",
        "def train_system(data_path, classes):\n",
        "\n",
        "    class_templates = {}\n",
        "    for class_name in classes:\n",
        "        print(f\"Processing class: {class_name}\")\n",
        "\n",
        "        # Get all WAV files in this class folder\n",
        "        class_path = os.path.join(data_path, class_name)\n",
        "        wav_files = sorted(glob.glob(os.path.join(class_path, \"*.wav\")))\n",
        "\n",
        "        # Process each file in this class\n",
        "        class_spectra = []\n",
        "        successful_files = 0\n",
        "\n",
        "        # Use only 0â€“799 for training\n",
        "        train_files = wav_files[:800]\n",
        "\n",
        "        for wav_file in train_files:\n",
        "            # Process one audio file\n",
        "            file_spectrum = process_audio_file(wav_file)\n",
        "\n",
        "            if file_spectrum is not None:\n",
        "                class_spectra.append(file_spectrum)\n",
        "                successful_files += 1\n",
        "\n",
        "        print(f\"  Successfully processed {successful_files}/{len(wav_files)} files\")\n",
        "\n",
        "        # Create class template by averaging all file spectra\n",
        "        if len(class_spectra) > 0:\n",
        "            class_template = np.mean(class_spectra, axis=0)\n",
        "            class_templates[class_name] = class_template\n",
        "            print(f\"  Created template with {len(class_template)} features\")\n",
        "        else:\n",
        "            print(f\"  Warning: No valid files for class {class_name}\")\n",
        "\n",
        "    return class_templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwV2r7mt0DzH",
        "outputId": "fda33e58-cd73-4ef0-b242-71899b9e5129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training phase...\n",
            "Processing class: yes\n",
            "  Successfully processed 800/1000 files\n",
            "  Created template with 128 features\n",
            "Processing class: no\n",
            "  Successfully processed 800/1000 files\n",
            "  Created template with 128 features\n",
            "Processing class: up\n",
            "  Successfully processed 800/1000 files\n",
            "  Created template with 128 features\n",
            "Processing class: down\n",
            "  Successfully processed 800/1000 files\n",
            "  Created template with 128 features\n",
            "Processing class: left\n",
            "  Successfully processed 800/1000 files\n",
            "  Created template with 128 features\n",
            "Processing class: right\n",
            "  Successfully processed 800/1000 files\n",
            "  Created template with 128 features\n",
            "Processing class: go\n",
            "  Successfully processed 800/1000 files\n",
            "  Created template with 128 features\n",
            "Processing class: stop\n",
            "  Successfully processed 800/1000 files\n",
            "  Created template with 128 features\n",
            "\n",
            "Training completed!\n",
            "Created templates for 8 classes\n"
          ]
        }
      ],
      "source": [
        "# Execute training\n",
        "print(\"Starting training phase...\")\n",
        "templates = train_system(DATA_PATH, CLASSES)\n",
        "\n",
        "print(f\"\\nTraining completed!\")\n",
        "print(f\"Created templates for {len(templates)} classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PzE07wG0HfC",
        "outputId": "2d9262cd-668e-4200-9921-826a84b5b9bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Templates saved to 'speech_templates.pkl'\n"
          ]
        }
      ],
      "source": [
        "# Save templates for later use\n",
        "with open('speech_templates.pkl', 'wb') as f:\n",
        "    pickle.dump(templates, f)\n",
        "\n",
        "print(\"Templates saved to 'speech_templates.pkl'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkCfPSIX2P6x"
      },
      "source": [
        "# **Testing Phase**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlBSsjx50a7R",
        "outputId": "c964b5ed-81b2-4fbb-fe23-d41ca1e03405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded templates for classes: ['yes', 'no', 'up', 'down', 'left', 'right', 'go', 'stop']\n"
          ]
        }
      ],
      "source": [
        "# Load the templates you created in training\n",
        "with open('speech_templates.pkl', 'rb') as f:\n",
        "    templates = pickle.load(f)\n",
        "\n",
        "print(\"Loaded templates for classes:\", list(templates.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3m3PGeh62d1w"
      },
      "outputs": [],
      "source": [
        "# Compute distance between two vectors\n",
        "def compute_distance(vector1, vector2, metric='euclidean'):\n",
        "\n",
        "    if metric == 'euclidean': # L2 distance\n",
        "        return np.sqrt(np.sum((vector1 - vector2) ** 2))\n",
        "\n",
        "    elif metric == 'manhattan': # L1 distance\n",
        "        return np.sum(np.abs(vector1 - vector2))\n",
        "\n",
        "    elif metric == 'cosine':\n",
        "        dot_product = np.dot(vector1, vector2)\n",
        "        norm1 = np.linalg.norm(vector1)\n",
        "        norm2 = np.linalg.norm(vector2)\n",
        "        return 1 - (dot_product / (norm1 * norm2))\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unknown metric\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GjeHuPpV2e-k"
      },
      "outputs": [],
      "source": [
        "# Predict the class of an unknown speech file\n",
        "def predict_speech(audio_file_path, templates, metric='euclidean'):\n",
        "\n",
        "    # Process the test file (same as training)\n",
        "    test_spectrum = process_audio_file(audio_file_path)\n",
        "\n",
        "    if test_spectrum is None:\n",
        "        return None\n",
        "\n",
        "    # Compute distance to each class template\n",
        "    distances = {}\n",
        "    for class_name, template in templates.items():\n",
        "        distance = compute_distance(test_spectrum, template, metric)\n",
        "        distances[class_name] = distance\n",
        "\n",
        "    # Pick class with smallest distance\n",
        "    predicted_class = min(distances, key=distances.get)\n",
        "\n",
        "    return predicted_class, distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4YMaKjru2jnE"
      },
      "outputs": [],
      "source": [
        "# Test the system on all test files and compute accuracy\n",
        "def test_system(data_path, templates, classes, metric='euclidean'):\n",
        "\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    file_paths = []\n",
        "\n",
        "    print(\"Starting testing phase...\")\n",
        "\n",
        "    for class_name in classes:\n",
        "        print(f\"Testing class: {class_name}\")\n",
        "        class_path = os.path.join(data_path, class_name)\n",
        "\n",
        "        # Load and sort wav files\n",
        "        wav_files = sorted(glob.glob(os.path.join(class_path, \"*.wav\")))\n",
        "\n",
        "        # files 0â€“799 train, 800â€“999 test\n",
        "        test_files = wav_files[800:1000]\n",
        "\n",
        "        for test_file in test_files:\n",
        "            # Get prediction\n",
        "            prediction, distances = predict_speech(test_file, templates, metric)\n",
        "\n",
        "            if prediction is not None:\n",
        "                true_labels.append(class_name)\n",
        "                predicted_labels.append(prediction)\n",
        "                file_paths.append(test_file)\n",
        "\n",
        "                # Optional: Print some predictions\n",
        "                if len(true_labels) % 100 == 0:\n",
        "                    print(f\"  Sample: {os.path.basename(test_file)}\")\n",
        "                    print(f\"    True: {class_name}, Predicted: {prediction}\")\n",
        "                    print(f\"    Distances: {dict(list(distances.items())[:2])}...\")\n",
        "\n",
        "    return true_labels, predicted_labels, file_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llvsBXlP2bvq"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A8fe82vl2kZO"
      },
      "outputs": [],
      "source": [
        "#Compute and display evaluation metrics\n",
        "def evaluate_performance(true_labels, predicted_labels, classes):\n",
        "\n",
        "    # Overall accuracy\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"ğŸ“Š FINAL RESULTS\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "    # Per-class accuracy\n",
        "    print(f\"\\nPer-class Accuracy:\")\n",
        "    cm = confusion_matrix(true_labels, predicted_labels, labels=classes)\n",
        "\n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_correct = cm[i, i]\n",
        "        class_total = np.sum(cm[i, :])\n",
        "        class_accuracy = class_correct / class_total if class_total > 0 else 0\n",
        "        print(f\"  {class_name:6}: {class_accuracy:.4f} ({class_correct}/{class_total})\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(\"True \\\\ Pred\", end=\"\")\n",
        "    for class_name in classes:\n",
        "        print(f\"{class_name:8}\", end=\"\")\n",
        "    print()\n",
        "\n",
        "    for i, true_class in enumerate(classes):\n",
        "        print(f\"{true_class:11}\", end=\"\")\n",
        "        for j in range(len(classes)):\n",
        "            print(f\"{cm[i, j]:8}\", end=\"\")\n",
        "        print()\n",
        "\n",
        "    return accuracy, cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRwHnJPe0zYG",
        "outputId": "0d5b8cef-0428-4797-ccb0-1cd11fd5ae97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing Distance-Based Speech Recognition ===\n",
            "Loaded templates for 8 classes\n",
            "\n",
            "========================================\n",
            "Testing with euclidean distance:\n",
            "========================================\n",
            "Starting testing phase...\n",
            "Testing class: yes\n",
            "  Sample: e7d0eb3f_nohash_0.wav\n",
            "    True: yes, Predicted: yes\n",
            "    Distances: {'yes': np.float64(4.03366885434509), 'no': np.float64(4.772526170469457)}...\n",
            "  Sample: ffd2ba2f_nohash_2.wav\n",
            "    True: yes, Predicted: yes\n",
            "    Distances: {'yes': np.float64(1.36645282084867), 'no': np.float64(2.239572092379814)}...\n",
            "Testing class: no\n",
            "  Sample: e53139ad_nohash_4.wav\n",
            "    True: no, Predicted: go\n",
            "    Distances: {'yes': np.float64(1.5416231991706757), 'no': np.float64(1.5446076385167504)}...\n",
            "  Sample: fffcabd1_nohash_0.wav\n",
            "    True: no, Predicted: yes\n",
            "    Distances: {'yes': np.float64(1.1503871560846637), 'no': np.float64(1.7202164286991537)}...\n",
            "Testing class: up\n",
            "  Sample: e62056e2_nohash_0.wav\n",
            "    True: up, Predicted: stop\n",
            "    Distances: {'yes': np.float64(6.203250851550998), 'no': np.float64(6.4487657083937995)}...\n",
            "  Sample: ffd2ba2f_nohash_3.wav\n",
            "    True: up, Predicted: up\n",
            "    Distances: {'yes': np.float64(1.4821872097408861), 'no': np.float64(1.9463538246711374)}...\n",
            "Testing class: down\n",
            "  Sample: e2362167_nohash_1.wav\n",
            "    True: down, Predicted: go\n",
            "    Distances: {'yes': np.float64(3.6392548155155318), 'no': np.float64(2.9293119299226222)}...\n",
            "  Sample: ffd2ba2f_nohash_4.wav\n",
            "    True: down, Predicted: no\n",
            "    Distances: {'yes': np.float64(2.059117363969608), 'no': np.float64(1.9200799359972374)}...\n",
            "Testing class: left\n",
            "  Sample: e77d88fc_nohash_0.wav\n",
            "    True: left, Predicted: down\n",
            "    Distances: {'yes': np.float64(4.156964985108892), 'no': np.float64(3.631971805446722)}...\n",
            "  Sample: ffd2ba2f_nohash_4.wav\n",
            "    True: left, Predicted: yes\n",
            "    Distances: {'yes': np.float64(1.3163737683057068), 'no': np.float64(2.0209590514805944)}...\n",
            "Testing class: right\n",
            "  Sample: e4b02540_nohash_0.wav\n",
            "    True: right, Predicted: down\n",
            "    Distances: {'yes': np.float64(2.0091557964273297), 'no': np.float64(1.2470759816331087)}...\n",
            "  Sample: ffd2ba2f_nohash_4.wav\n",
            "    True: right, Predicted: yes\n",
            "    Distances: {'yes': np.float64(1.376991966789283), 'no': np.float64(1.6765623705669044)}...\n",
            "Testing class: go\n",
            "  Sample: e41e41f7_nohash_1.wav\n",
            "    True: go, Predicted: up\n",
            "    Distances: {'yes': np.float64(2.0545418029957774), 'no': np.float64(2.931577595266993)}...\n",
            "  Sample: ffd2ba2f_nohash_3.wav\n",
            "    True: go, Predicted: yes\n",
            "    Distances: {'yes': np.float64(1.6705409675987934), 'no': np.float64(1.7747867249516291)}...\n",
            "Testing class: stop\n",
            "  Sample: e7ea8b76_nohash_0.wav\n",
            "    True: stop, Predicted: up\n",
            "    Distances: {'yes': np.float64(1.5397955918265265), 'no': np.float64(2.3960572523841503)}...\n",
            "  Sample: fffcabd1_nohash_1.wav\n",
            "    True: stop, Predicted: up\n",
            "    Distances: {'yes': np.float64(1.4331651709005515), 'no': np.float64(2.1994422196149914)}...\n",
            "\n",
            "==================================================\n",
            "ğŸ“Š FINAL RESULTS\n",
            "==================================================\n",
            "Overall Accuracy: 0.2500 (25.00%)\n",
            "\n",
            "Per-class Accuracy:\n",
            "  yes   : 0.3350 (67/200)\n",
            "  no    : 0.1450 (29/200)\n",
            "  up    : 0.6850 (137/200)\n",
            "  down  : 0.2200 (44/200)\n",
            "  left  : 0.0350 (7/200)\n",
            "  right : 0.0800 (16/200)\n",
            "  go    : 0.2500 (50/200)\n",
            "  stop  : 0.2500 (50/200)\n",
            "\n",
            "Confusion Matrix:\n",
            "True \\ Predyes     no      up      down    left    right   go      stop    \n",
            "yes              67       5      85      12       5       5      18       3\n",
            "no               26      29      71      28       9       5      29       3\n",
            "up                1       3     137      17       4       1       4      33\n",
            "down             10      20      86      44      11       8       9      12\n",
            "left             11      17     107      30       7       9      11       8\n",
            "right            23      12      94      24       3      16      25       3\n",
            "go               17      13      90       7       3       8      50      12\n",
            "stop              3       3     105      26       0       5       8      50\n",
            "\n",
            "========================================\n",
            "Testing with manhattan distance:\n",
            "========================================\n",
            "Starting testing phase...\n",
            "Testing class: yes\n",
            "  Sample: e7d0eb3f_nohash_0.wav\n",
            "    True: yes, Predicted: yes\n",
            "    Distances: {'yes': np.float64(35.644215909702964), 'no': np.float64(44.886219350323316)}...\n",
            "  Sample: ffd2ba2f_nohash_2.wav\n",
            "    True: yes, Predicted: yes\n",
            "    Distances: {'yes': np.float64(10.334207990772935), 'no': np.float64(16.201787019586924)}...\n",
            "Testing class: no\n",
            "  Sample: e53139ad_nohash_4.wav\n",
            "    True: no, Predicted: go\n",
            "    Distances: {'yes': np.float64(13.202575277151038), 'no': np.float64(8.611501589406508)}...\n",
            "  Sample: fffcabd1_nohash_0.wav\n",
            "    True: no, Predicted: up\n",
            "    Distances: {'yes': np.float64(10.555697123311614), 'no': np.float64(8.981712341339655)}...\n",
            "Testing class: up\n",
            "  Sample: e62056e2_nohash_0.wav\n",
            "    True: up, Predicted: up\n",
            "    Distances: {'yes': np.float64(20.879980423489627), 'no': np.float64(19.833368337777475)}...\n",
            "  Sample: ffd2ba2f_nohash_3.wav\n",
            "    True: up, Predicted: up\n",
            "    Distances: {'yes': np.float64(13.360970958989583), 'no': np.float64(9.376549784012823)}...\n",
            "Testing class: down\n",
            "  Sample: e2362167_nohash_1.wav\n",
            "    True: down, Predicted: go\n",
            "    Distances: {'yes': np.float64(16.80294027283866), 'no': np.float64(11.543949781630989)}...\n",
            "  Sample: ffd2ba2f_nohash_4.wav\n",
            "    True: down, Predicted: up\n",
            "    Distances: {'yes': np.float64(13.395817967111073), 'no': np.float64(8.907506475374648)}...\n",
            "Testing class: left\n",
            "  Sample: e77d88fc_nohash_0.wav\n",
            "    True: left, Predicted: down\n",
            "    Distances: {'yes': np.float64(21.978407702588463), 'no': np.float64(19.017116178455666)}...\n",
            "  Sample: ffd2ba2f_nohash_4.wav\n",
            "    True: left, Predicted: up\n",
            "    Distances: {'yes': np.float64(10.641056753677185), 'no': np.float64(10.53793658232092)}...\n",
            "Testing class: right\n",
            "  Sample: e4b02540_nohash_0.wav\n",
            "    True: right, Predicted: down\n",
            "    Distances: {'yes': np.float64(11.440250655218641), 'no': np.float64(7.972864051117073)}...\n",
            "  Sample: ffd2ba2f_nohash_4.wav\n",
            "    True: right, Predicted: up\n",
            "    Distances: {'yes': np.float64(11.68963032530289), 'no': np.float64(8.363074628205911)}...\n",
            "Testing class: go\n",
            "  Sample: e41e41f7_nohash_1.wav\n",
            "    True: go, Predicted: up\n",
            "    Distances: {'yes': np.float64(16.66547632011241), 'no': np.float64(15.864667849396398)}...\n",
            "  Sample: ffd2ba2f_nohash_3.wav\n",
            "    True: go, Predicted: go\n",
            "    Distances: {'yes': np.float64(13.393612677453115), 'no': np.float64(9.853939779555928)}...\n",
            "Testing class: stop\n",
            "  Sample: e7ea8b76_nohash_0.wav\n",
            "    True: stop, Predicted: up\n",
            "    Distances: {'yes': np.float64(12.65929854847059), 'no': np.float64(12.569001768248182)}...\n",
            "  Sample: fffcabd1_nohash_1.wav\n",
            "    True: stop, Predicted: up\n",
            "    Distances: {'yes': np.float64(10.092844204136501), 'no': np.float64(11.612810379019445)}...\n",
            "\n",
            "==================================================\n",
            "ğŸ“Š FINAL RESULTS\n",
            "==================================================\n",
            "Overall Accuracy: 0.2537 (25.37%)\n",
            "\n",
            "Per-class Accuracy:\n",
            "  yes   : 0.2850 (57/200)\n",
            "  no    : 0.1800 (36/200)\n",
            "  up    : 0.8400 (168/200)\n",
            "  down  : 0.2150 (43/200)\n",
            "  left  : 0.0300 (6/200)\n",
            "  right : 0.0700 (14/200)\n",
            "  go    : 0.2050 (41/200)\n",
            "  stop  : 0.2050 (41/200)\n",
            "\n",
            "Confusion Matrix:\n",
            "True \\ Predyes     no      up      down    left    right   go      stop    \n",
            "yes              57       2     104      14      10       3       8       2\n",
            "no                0      36      99      34       3       2      24       2\n",
            "up                1       8     168      10       0       0       3      10\n",
            "down              0      19     107      43       5       9      12       5\n",
            "left              4      24     123      26       6       5       7       5\n",
            "right             1      12     116      30       6      14      19       2\n",
            "go                0      15     117      17       1       6      41       3\n",
            "stop              7       6     119      19       0       2       6      41\n",
            "\n",
            "========================================\n",
            "Testing with cosine distance:\n",
            "========================================\n",
            "Starting testing phase...\n",
            "Testing class: yes\n",
            "  Sample: e7d0eb3f_nohash_0.wav\n",
            "    True: yes, Predicted: yes\n",
            "    Distances: {'yes': np.float64(0.37060926794145044), 'no': np.float64(0.5965874002937512)}...\n",
            "  Sample: ffd2ba2f_nohash_2.wav\n",
            "    True: yes, Predicted: yes\n",
            "    Distances: {'yes': np.float64(0.19146590437062105), 'no': np.float64(0.28485987988483585)}...\n",
            "Testing class: no\n",
            "  Sample: e53139ad_nohash_4.wav\n",
            "    True: no, Predicted: go\n",
            "    Distances: {'yes': np.float64(0.17525132049318204), 'no': np.float64(0.12506841122021972)}...\n",
            "  Sample: fffcabd1_nohash_0.wav\n",
            "    True: no, Predicted: no\n",
            "    Distances: {'yes': np.float64(0.12932862652713528), 'no': np.float64(0.08895411608019577)}...\n",
            "Testing class: up\n",
            "  Sample: e62056e2_nohash_0.wav\n",
            "    True: up, Predicted: stop\n",
            "    Distances: {'yes': np.float64(0.6925783813029132), 'no': np.float64(0.7357154287623584)}...\n",
            "  Sample: ffd2ba2f_nohash_3.wav\n",
            "    True: up, Predicted: up\n",
            "    Distances: {'yes': np.float64(0.23535493912436756), 'no': np.float64(0.15411137577326284)}...\n",
            "Testing class: down\n",
            "  Sample: e2362167_nohash_1.wav\n",
            "    True: down, Predicted: go\n",
            "    Distances: {'yes': np.float64(0.13797161340630637), 'no': np.float64(0.10255500590899591)}...\n",
            "  Sample: ffd2ba2f_nohash_4.wav\n",
            "    True: down, Predicted: no\n",
            "    Distances: {'yes': np.float64(0.2399844114683044), 'no': np.float64(0.18276854610655457)}...\n",
            "Testing class: left\n",
            "  Sample: e77d88fc_nohash_0.wav\n",
            "    True: left, Predicted: left\n",
            "    Distances: {'yes': np.float64(0.1398556219653836), 'no': np.float64(0.14376032802566763)}...\n",
            "  Sample: ffd2ba2f_nohash_4.wav\n",
            "    True: left, Predicted: no\n",
            "    Distances: {'yes': np.float64(0.17606870025920152), 'no': np.float64(0.1745594491826078)}...\n",
            "Testing class: right\n",
            "  Sample: e4b02540_nohash_0.wav\n",
            "    True: right, Predicted: down\n",
            "    Distances: {'yes': np.float64(0.0884720339202576), 'no': np.float64(0.04420126301146776)}...\n",
            "  Sample: ffd2ba2f_nohash_4.wav\n",
            "    True: right, Predicted: go\n",
            "    Distances: {'yes': np.float64(0.17744265813158944), 'no': np.float64(0.13939421327445978)}...\n",
            "Testing class: go\n",
            "  Sample: e41e41f7_nohash_1.wav\n",
            "    True: go, Predicted: go\n",
            "    Distances: {'yes': np.float64(0.13617364067324889), 'no': np.float64(0.10910273820892846)}...\n",
            "  Sample: ffd2ba2f_nohash_3.wav\n",
            "    True: go, Predicted: go\n",
            "    Distances: {'yes': np.float64(0.19582502122276935), 'no': np.float64(0.16793451581696694)}...\n",
            "Testing class: stop\n",
            "  Sample: e7ea8b76_nohash_0.wav\n",
            "    True: stop, Predicted: go\n",
            "    Distances: {'yes': np.float64(0.12313266159106162), 'no': np.float64(0.11860552949485326)}...\n",
            "  Sample: fffcabd1_nohash_1.wav\n",
            "    True: stop, Predicted: stop\n",
            "    Distances: {'yes': np.float64(0.19511756001715097), 'no': np.float64(0.18791099534619027)}...\n",
            "\n",
            "==================================================\n",
            "ğŸ“Š FINAL RESULTS\n",
            "==================================================\n",
            "Overall Accuracy: 0.3800 (38.00%)\n",
            "\n",
            "Per-class Accuracy:\n",
            "  yes   : 0.5950 (119/200)\n",
            "  no    : 0.4650 (93/200)\n",
            "  up    : 0.5250 (105/200)\n",
            "  down  : 0.2200 (44/200)\n",
            "  left  : 0.1500 (30/200)\n",
            "  right : 0.2250 (45/200)\n",
            "  go    : 0.4950 (99/200)\n",
            "  stop  : 0.3650 (73/200)\n",
            "\n",
            "Confusion Matrix:\n",
            "True \\ Predyes     no      up      down    left    right   go      stop    \n",
            "yes             119      12       9       2      10      10      24      14\n",
            "no                6      93      18      17      11      11      35       9\n",
            "up               11      11     105      13       5       4      13      38\n",
            "down             13      45      26      44      10      20      13      29\n",
            "left             24      30      37      13      30      24      17      25\n",
            "right            20      34      19      10      10      45      43      19\n",
            "go                5      30      22       5       9      16      99      14\n",
            "stop             18      10      64      11       5       1      18      73\n",
            "\n",
            "ğŸ¯ BEST PERFORMANCE: 0.3800 with cosine distance\n",
            "âœ… Test results saved to 'test_results.pkl'\n"
          ]
        }
      ],
      "source": [
        "print(\"=== Testing Distance-Based Speech Recognition ===\")\n",
        "\n",
        "# Load templates\n",
        "with open('speech_templates.pkl', 'rb') as f:\n",
        "  templates = pickle.load(f)\n",
        "\n",
        "print(f\"Loaded templates for {len(templates)} classes\")\n",
        "\n",
        "# Test with different distance metrics\n",
        "metrics = ['euclidean', 'manhattan', 'cosine']\n",
        "\n",
        "best_accuracy = 0\n",
        "best_metric = None\n",
        "\n",
        "for metric in metrics:\n",
        "  print(f\"\\n{'='*40}\")\n",
        "  print(f\"Testing with {metric} distance:\")\n",
        "  print(f\"{'='*40}\")\n",
        "\n",
        "  true_labels, predicted_labels, file_paths = test_system(DATA_PATH, templates, CLASSES, metric=metric)\n",
        "\n",
        "  accuracy, cm = evaluate_performance(true_labels, predicted_labels, CLASSES)\n",
        "\n",
        "  if accuracy > best_accuracy:\n",
        "    best_accuracy = accuracy\n",
        "    best_metric = metric\n",
        "\n",
        "print(f\"\\nğŸ¯ BEST PERFORMANCE: {best_accuracy:.4f} with {best_metric} distance\")\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "  'true_labels': true_labels,\n",
        "  'predicted_labels': predicted_labels,\n",
        "  'file_paths': file_paths,\n",
        "  'accuracy': best_accuracy,\n",
        "  'best_metric': best_metric\n",
        "  }\n",
        "\n",
        "with open('test_results.pkl', 'wb') as f:\n",
        "  pickle.dump(results, f)\n",
        "\n",
        "print(\"âœ… Test results saved to 'test_results.pkl'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO9wpd0EUlpk"
      },
      "source": [
        "# **CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWvE0_35UyRw"
      },
      "source": [
        "## Load WAV â†’ Mel Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Oyh3WyMSUCX5"
      },
      "outputs": [],
      "source": [
        "def extract_mel_spectrogram(file_path):\n",
        "    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "    # Compute Mel spectrogram\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=signal,\n",
        "        sr=SAMPLE_RATE,\n",
        "        n_fft=512,\n",
        "        hop_length=160,\n",
        "        n_mels=N_MELS\n",
        "    )\n",
        "\n",
        "    # Convert to log scale\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "    # Normalize\n",
        "    mel_db = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min())\n",
        "\n",
        "    return mel_db.T   # Shape: (time, mel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYZzpRXsU2jP"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vqaHDjdrUEn7"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for label_idx, class_name in enumerate(CLASSES):\n",
        "        class_path = os.path.join(DATA_PATH, class_name)\n",
        "        wav_files = sorted([f for f in os.listdir(class_path) if f.endswith(\".wav\")])\n",
        "\n",
        "        for file in wav_files:\n",
        "            mel = extract_mel_spectrogram(os.path.join(class_path, file))\n",
        "            X.append(mel)\n",
        "            y.append(label_idx)\n",
        "\n",
        "    return X, np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODkqRszSU5dG"
      },
      "source": [
        "## Pad sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MjBb8Y4qUHMG"
      },
      "outputs": [],
      "source": [
        "def pad_spectrograms(X):\n",
        "    max_len = max([x.shape[0] for x in X])\n",
        "    padded = []\n",
        "\n",
        "    for m in X:\n",
        "        pad_width = max_len - m.shape[0]\n",
        "        padded.append(np.pad(m, ((0, pad_width), (0,0)), mode='constant'))\n",
        "\n",
        "    return np.array(padded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Kuh2_2U8pp"
      },
      "source": [
        "## Prepare data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "H7L4yq26UJFZ"
      },
      "outputs": [],
      "source": [
        "X, y = load_dataset()\n",
        "X = pad_spectrograms(X)\n",
        "\n",
        "# Add channel dimension for CNN\n",
        "X = X[..., np.newaxis]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqzPuubGU_Z-"
      },
      "source": [
        "## Build the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "9BHpis9kUKyG",
        "outputId": "c2153bdd-1cdd-4b33-a897-799ac967d06c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPool2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPool2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPool2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"Adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aExDIWLVCpU"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xaVG2NHUMuN",
        "outputId": "088f40e2-6f7e-48a1-988b-d9f719e73ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2573 - loss: 1.9015 - val_accuracy: 0.6180 - val_loss: 1.0969\n",
            "Epoch 2/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6299 - loss: 1.0684 - val_accuracy: 0.7984 - val_loss: 0.6617\n",
            "Epoch 3/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7552 - loss: 0.7034 - val_accuracy: 0.8375 - val_loss: 0.5228\n",
            "Epoch 4/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.5234 - val_accuracy: 0.8609 - val_loss: 0.4312\n",
            "Epoch 5/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8488 - loss: 0.4276 - val_accuracy: 0.8617 - val_loss: 0.4087\n",
            "Epoch 6/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8854 - loss: 0.3385 - val_accuracy: 0.8805 - val_loss: 0.3607\n",
            "Epoch 7/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.2830 - val_accuracy: 0.8828 - val_loss: 0.3535\n",
            "Epoch 8/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9163 - loss: 0.2364 - val_accuracy: 0.8977 - val_loss: 0.3079\n",
            "Epoch 9/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9242 - loss: 0.2051 - val_accuracy: 0.8898 - val_loss: 0.3353\n",
            "Epoch 10/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9348 - loss: 0.1805 - val_accuracy: 0.8938 - val_loss: 0.3349\n",
            "Epoch 11/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1631 - val_accuracy: 0.9000 - val_loss: 0.3468\n",
            "Epoch 12/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9482 - loss: 0.1357 - val_accuracy: 0.8719 - val_loss: 0.3960\n",
            "Epoch 13/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9538 - loss: 0.1303 - val_accuracy: 0.9008 - val_loss: 0.3558\n",
            "Epoch 14/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9596 - loss: 0.1009 - val_accuracy: 0.8883 - val_loss: 0.4096\n",
            "Epoch 15/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9634 - loss: 0.1006 - val_accuracy: 0.8945 - val_loss: 0.3988\n",
            "Epoch 16/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9658 - loss: 0.0932 - val_accuracy: 0.9047 - val_loss: 0.3775\n",
            "Epoch 17/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9621 - loss: 0.1101 - val_accuracy: 0.8914 - val_loss: 0.4380\n",
            "Epoch 18/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9731 - loss: 0.0741 - val_accuracy: 0.9086 - val_loss: 0.4004\n",
            "Epoch 19/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9704 - loss: 0.0802 - val_accuracy: 0.9102 - val_loss: 0.3623\n",
            "Epoch 20/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9800 - loss: 0.0637 - val_accuracy: 0.8992 - val_loss: 0.4243\n",
            "Epoch 21/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9743 - loss: 0.0700 - val_accuracy: 0.8969 - val_loss: 0.4040\n",
            "Epoch 22/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9844 - loss: 0.0558 - val_accuracy: 0.8977 - val_loss: 0.4313\n",
            "Epoch 23/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0501 - val_accuracy: 0.9070 - val_loss: 0.4352\n",
            "Epoch 24/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9778 - loss: 0.0580 - val_accuracy: 0.9039 - val_loss: 0.4481\n",
            "Epoch 25/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9777 - loss: 0.0605 - val_accuracy: 0.9070 - val_loss: 0.4233\n",
            "Epoch 26/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9804 - loss: 0.0622 - val_accuracy: 0.9109 - val_loss: 0.4104\n",
            "Epoch 27/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.0538 - val_accuracy: 0.9164 - val_loss: 0.4488\n",
            "Epoch 28/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 0.0530 - val_accuracy: 0.9016 - val_loss: 0.4438\n",
            "Epoch 29/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0480 - val_accuracy: 0.9070 - val_loss: 0.4266\n",
            "Epoch 30/30\n",
            "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.0573 - val_accuracy: 0.9039 - val_loss: 0.4569\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCvElNT0VGpO"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLF14AMgUQpH",
        "outputId": "a3f5c3d6-e731-4a6c-b937-7529ca3c6d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.5731\n",
            "Test Accuracy: 90.81%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UafXtSg1VLRE"
      },
      "source": [
        "## Predict a single WAV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SgR90-iyUR3V"
      },
      "outputs": [],
      "source": [
        "def predict_file(path):\n",
        "    mel = extract_mel_spectrogram(path)\n",
        "    mel = np.pad(mel, ((0, X.shape[1] - mel.shape[0]), (0, 0)))\n",
        "    mel = mel[np.newaxis, ..., np.newaxis]\n",
        "    probs = model.predict(mel)[0]\n",
        "    pred = np.argmax(probs)\n",
        "    return CLASSES[pred], probs[pred]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}